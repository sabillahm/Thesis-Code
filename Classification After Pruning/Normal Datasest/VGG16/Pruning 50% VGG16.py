# -*- coding: utf-8 -*-
"""5 iteration-best acc-Pruning VGG 50% Percobaan 6 Fix.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WXbH1PxDiUZJYOm5H8Qnstdq0B-UuUWK

5 iterasi - akurasi terbaik


souce code utama, dilatih selama 5 iterasi

# Cell 1: Import Libraries and Setup Device
'''
This cell imports all the necessary libraries and sets up the device for GPU computation if available.
We are using PyTorch for deep learning, OpenCV for image processing, and Matplotlib/Seaborn for visualization.
'''
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import models, transforms
import cv2
from torchvision.transforms import v2
import matplotlib.pyplot as plt
import matplotlib.patheffects as path_effects
from tqdm import tqdm
import os
import numpy as np
import time
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns

# Cek apakah kode dijalankan di Google Colab
IN_COLAB = 'google.colab' in str(get_ipython())

# Cek apakah GPU tersedia, jika tidak gunakan CPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {device}')

# Mount Google Drive jika menggunakan Google Colab
if IN_COLAB:
    from google.colab import drive
    drive.mount('/content/drive')

"""# Cell 2: Define Data Loading and Preprocessing Functions
'''
This cell contains functions to load and preprocess images from the dataset.
The `load_data` function loads images from the specified directory and assigns labels based on the folder structure.
The `preprocess_image` function applies CLAHE and unsharp masking to enhance image quality.
The `CustomDataset` class integrates these functions and prepares the dataset for use in PyTorch.
'''
"""

def load_data(dataset_path, subset):
    images = []
    labels = []

    # Tentukan label sesuai dengan subset

    label_names = ['adenocarcinoma', 'large.cell.carcinoma', 'normal', 'squamous.cell.carcinoma']



    # Pemetaan nama label ke indeks
    label_map = {name: idx for idx, name in enumerate(label_names)}

    subset_path = os.path.join(dataset_path, subset)
    for label_name in label_names:
        image_dir = os.path.join(subset_path, label_name)
        if not os.path.exists(image_dir):
            raise FileNotFoundError(f"Directory not found: {image_dir}")
        for file_name in os.listdir(image_dir):
            if file_name.endswith('.png'):  # Cek jika file adalah gambar PNG
                image_path = os.path.join(image_dir, file_name)
                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
                if image is None:
                    print(f"Warning: Unable to load image {image_path}")
                    continue
                images.append(image)
                labels.append(label_map[label_name])
                print(f"Loaded image {image_path}")
    return images, labels

def preprocess_image(image):
    if image is None or image.size == 0:
        raise ValueError("Empty image provided for preprocessing")

    # Terapkan CLAHE untuk meningkatkan kontras
    #clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(10, 10))

    clahe_image = clahe.apply(image)

    # Terapkan Gaussian Blur untuk menghaluskan gambar
    #gaussian = cv2.GaussianBlur(image, (9, 9), 10.0)
    # Terapkan Unsharp Masking untuk meningkatkan ketajaman gambar
    #unsharp_image = cv2.addWeighted(clahe_image, 1.5, gaussian, -0.5, 0, clahe_image)
    #unsharp_image = cv2.addWeighted(gaussian, 1.5, gaussian, -0.5, 0)

    return clahe_image

class CustomDataset(Dataset):
    def __init__(self, images, labels, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]
        try:
            # Proses gambar
            image = preprocess_image(image)
        except ValueError as e:
            print(f"Error preprocessing image at index {idx}: {e}")
            plt.imshow(image, cmap='gray')
            plt.title(f"Label: {label}")
            plt.show()
            raise e
        # Terapkan transformasi jika ada
        if self.transform:
            image = self.transform(image)
        if image.dim() == 2:  # Pastikan gambar memiliki 3 dimensi
            image = image.unsqueeze(0)
        return image, label

"""# Cell 3: Load and Transform Data
'''
This cell loads the data and applies the necessary transformations.
The dataset is divided into training, validation, and test sets.
Each image is transformed into a 224x224 size tensor suitable for input to the VGG-16 model.
'''
"""

# Mengatur path dataset, disesuaikan untuk Google Colab atau Jupyter Notebook
dataset_path = '/content/drive/MyDrive/Chest-CT-Data'

# Load data
train_images, train_labels = load_data(dataset_path, 'train')
valid_images, valid_labels = load_data(dataset_path, 'valid')
test_images, test_labels = load_data(dataset_path, 'test')

print(f"Loaded {len(train_images)} training images with {len(train_labels)} labels")
print(f"Loaded {len(valid_images)} validation images with {len(valid_labels)} labels")
print(f"Loaded {len(test_images)} test images with {len(test_labels)} labels")

# Transformasi data untuk persiapan training, validation, dan testing
transform = transforms.Compose([
    transforms.ToPILImage(),             # Ubah dari array NumPy ke gambar PIL
    transforms.Resize((224, 224)),       # Ubah ukuran gambar menjadi 224x224
    #v2.RandomHorizontalFlip(),           # Randomly flip the image horizontally
   # v2.RandomRotation(15),                # Randomly rotate the image by up to 15 degrees
    transforms.ToTensor(),               # Ubah gambar menjadi Tensor and normalize to [0, 1]
])

# Membuat dataset dan data loader untuk training, validation, dan testing
train_dataset = CustomDataset(train_images, train_labels, transform=transform)
valid_dataset = CustomDataset(valid_images, valid_labels, transform=transform)
test_dataset = CustomDataset(test_images, test_labels, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # DataLoader untuk training
valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False) # DataLoader untuk validasi
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)   # DataLoader untuk testing

"""## Pruning"""

import torch
import torch.nn as nn

# Fungsi untuk pruning layer Conv2D berdasarkan L2 norm
def l2_prune_conv2d_layer(module, pruning_amount):
    with torch.no_grad():
        weight = module.weight.data.view(module.weight.size(0), -1)
        l2_norms = torch.norm(weight, p=2, dim=1)

    num_filters = module.weight.size(0)
    num_prune = int(pruning_amount * num_filters)

    if num_prune == 0:
        return module, module.out_channels  # Tidak ada pruning jika num_prune adalah 0

    prune_indices = torch.argsort(l2_norms)[:num_prune]
    keep_indices = torch.argsort(l2_norms)[num_prune:]

    # Membentuk ulang layer Conv2D dengan filter yang dipertahankan
    new_conv = nn.Conv2d(
        in_channels=module.in_channels,
        out_channels=num_filters - num_prune,
        kernel_size=module.kernel_size,
        stride=module.stride,
        padding=module.padding,
        bias=module.bias is not None
    )

    new_conv.weight.data = module.weight.data[keep_indices].clone()
    if module.bias is not None:
        new_conv.bias.data = module.bias.data[keep_indices].clone()

    return new_conv, new_conv.out_channels

# Fungsi untuk mengganti layer secara rekursif dalam model
def replace_layers(module, pruning_amount=0.5):
    prev_out_channels = None

    for name, child in module.named_children():
        if isinstance(child, nn.Conv2d):
            # Prune the Conv2D layer and replace it
            pruned_layer, new_out_channels = l2_prune_conv2d_layer(child, pruning_amount)

            # Jika ada layer sebelumnya, sesuaikan in_channels dari layer saat ini
            if prev_out_channels is not None:
                pruned_layer = nn.Conv2d(
                    in_channels=prev_out_channels,  # Sesuaikan dengan output layer sebelumnya
                    out_channels=new_out_channels,
                    kernel_size=child.kernel_size,
                    stride=child.stride,
                    padding=child.padding,
                    bias=child.bias is not None
                )
                pruned_layer.weight.data = child.weight.data[:new_out_channels, :prev_out_channels].clone()
                if pruned_layer.bias is not None:
                    pruned_layer.bias.data = child.bias.data[:new_out_channels].clone()

            setattr(module, name, pruned_layer)

            # Update jumlah channel output untuk layer berikutnya
            prev_out_channels = new_out_channels

        elif isinstance(child, nn.Sequential) or isinstance(child, nn.Module):
            # Recursive call for nested Sequential or Module
            replace_layers(child, pruning_amount)

# Fungsi untuk menyesuaikan layer klasifikasi (fully connected) dalam model
def adjust_classifier(model):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    with torch.no_grad():
        dummy_input = torch.randn(1, 3, 224, 224).to(device)  # Sesuaikan ukuran input jika perlu
        features_output = model.features(dummy_input)
        flattened_size = features_output.view(features_output.size(0), -1).size(1)

    first_linear = None
    for module in model.classifier:
        if isinstance(module, nn.Linear):
            first_linear = module
            break

    if first_linear is not None:
        new_linear = nn.Linear(flattened_size, first_linear.out_features).to(device)
        with torch.no_grad():
            new_linear.weight.data[:, :min(flattened_size, first_linear.in_features)] = \
                first_linear.weight.data[:, :min(flattened_size, first_linear.in_features)]
            new_linear.bias.data = first_linear.bias.data

        for i, module in enumerate(model.classifier):
            if module is first_linear:
                model.classifier[i] = new_linear
                break

        print(f"Adjusted classifier input size to {flattened_size}")
    else:
        print("No Linear layer found in classifier. The model structure might need manual adjustment.")

# Fungsi untuk pruning model yang telah dilatih
def prune_trained_model(model, pruning_amount=0.1):
    replace_layers(model.features, pruning_amount)
    adjust_classifier(model)
    return model

def load_and_prune_model(model_path, model_class, pruning_ratio):

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load model
    state_dict = torch.load(model_path)
    model = model_class().to(device)
    model.load_state_dict(state_dict)
    print("Original model loaded.")

    # Prune model
    pruned_model =  prune_trained_model(model, pruning_ratio).to(device)
    print("Model pruned.")
    return pruned_model



def calculate_model_size(model):
    """
    Calculate the size of the model in megabytes (MB).

    Args:
    - model: The model (before or after pruning).

    Returns:
    - size_in_mb: The size of the model in MB.
    """
    param_size = sum(param.numel() * param.element_size() for param in model.parameters())
    buffer_size = sum(buffer.numel() * buffer.element_size() for buffer in model.buffers())
    size_in_bytes = param_size + buffer_size
    size_in_mb = size_in_bytes / 1024**2  # Convert bytes to megabytes (MB)
    return size_in_mb

# Fungsi untuk memverifikasi pruning model
def verify_pruned_model(model, original_model):
    def calculate_num_params(model):
        return sum(p.numel() for p in model.parameters())

    # Calculate the model sizes
    original_size = calculate_model_size(original_model)
    pruned_size = calculate_model_size(model)
    print(f"Original model size: {original_size:.2f} MB")
    print(f"Pruned model size: {pruned_size:.2f} MB")
    print(f"Size reduction: {original_size - pruned_size:.2f} MB ({(original_size - pruned_size) / original_size * 100:.2f}%)")

    original_params = calculate_num_params(original_model)
    pruned_params = calculate_num_params(model)
    print(f"Original model parameters: {original_params}")
    print(f"Pruned model parameters: {pruned_params}")

    print("\nLayer-wise dimension comparison:")
    for (orig_name, orig_module), (pruned_name, pruned_module) in zip(original_model.features.named_modules(), model.features.named_modules()):
        if isinstance(orig_module, nn.Conv2d) and isinstance(pruned_module, nn.Conv2d):
            print(f"Layer: {orig_name}")
            print(f"  - Original shape: {orig_module.weight.shape}")
            print(f"  - Pruned shape: {pruned_module.weight.shape}")

# Custom Model dengan VGG16 feature extractor + Fully Connected Layers untuk klasifikasi
class VGG16(nn.Module):
    def __init__(self):
        super(VGG16, self).__init__()
        # Feature extractor dari VGG16
        vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)
        vgg16_features = nn.Sequential(*list(vgg16.features.children()))
        self.features = vgg16_features

        #self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # Global average pooling
        # Fully connected layers untuk klasifikasi
        self.classifier = nn.Sequential(
            nn.Flatten(),
            #nn.Linear(512 * 7 * 7),  # Input size 512 after global average pooling
            nn.Linear(512 * 7 * 7, 512),  # Sesuaikan input sesuai dengan output dari feature extractor VGG16
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, 4)
        )

    def forward(self, input):
        # Step 1: Input goes through VGG16 feature extractor
        x = self.features(input)

        # Step 3: Output of VGG16 features goes through classifier
        x = self.classifier(x)  # Klasifikasi
        return x

import copy

# Muat model hasil training Anda
model_path = '/content/drive/MyDrive/best-model-vgg-clahe-0,001.pth'
model = VGG16()
model.load_state_dict(torch.load(model_path, map_location=device))

# Buat salinan model asli
original_model_copy = copy.deepcopy(model)

# Prune model yang telah dilatih
pruning_ratio = 0.5
pruned_model = load_and_prune_model(model_path, VGG16, pruning_ratio)

# Verifikasi apakah model berhasil di-prune
verify_pruned_model(pruned_model, model)
torch.save(pruned_model.state_dict(), '/content/drive/MyDrive/Best-pruning-model/pruned-vgg-50.pth')

import time  # Import modul time

# Define the optimizer and loss function
optimizer = optim.SGD(pruned_model.parameters(), lr=0.001, momentum=0.8)
criterion = nn.CrossEntropyLoss()

# Function to calculate metrics (accuracy, precision, recall, F1-score)
def calculate_metrics(predictions, labels):
    preds = torch.argmax(predictions, dim=1).cpu().numpy()
    labels = labels.cpu().numpy()

    accuracy = (preds == labels).mean() * 100
    precision = precision_score(labels, preds, average='weighted', zero_division=1)
    recall = recall_score(labels, preds, average='weighted', zero_division=1)
    f1 = f1_score(labels, preds, average='weighted', zero_division=1)

    return accuracy, precision, recall, f1

# Function to train and evaluate the model
def train_and_evaluate(pruned_model, train_loader, valid_loader,  num_epochs=100):
    train_losses = []
    valid_losses = []
    train_accuracies = []
    valid_accuracies = []
    all_train_precisions = []
    all_train_recalls = []
    all_train_f1s = []
    all_valid_precisions = []
    all_valid_recalls = []
    all_valid_f1s = []

    best_valid_loss = float('inf')

    # Variable to accumulate total training and validation time
    total_train_validation_time = 0

    for epoch in range(1, num_epochs + 1):
        print(f'Epoch {epoch}/{num_epochs}')

        # Start timer for both training and validation
        start_epoch_time = time.time()

        # Training
        pruned_model.train()
        train_loss = 0
        all_train_preds = []
        all_train_labels = []
        for images, labels in tqdm(train_loader, desc='Training'):
            images, labels = images.to(device), labels.to(device)

            # Convert grayscale images to 3 channels
            if images.size(1) == 1:  # If single channel
                images = images.repeat(1, 3, 1, 1)  # Repeat the channel dimension 3 times

            optimizer.zero_grad()
            outputs = pruned_model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

            all_train_preds.append(outputs)
            all_train_labels.append(labels)

        train_loss /= len(train_loader)
        train_losses.append(train_loss)
        train_accuracy, train_precision, train_recall, train_f1 = calculate_metrics(torch.cat(all_train_preds), torch.cat(all_train_labels))
        train_accuracies.append(train_accuracy)
        all_train_precisions.append(train_precision) # Store train_precision
        all_train_recalls.append(train_recall)       # Store train_recall
        all_train_f1s.append(train_f1)             # Store train_f1

        print(f"Training Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1-Score: {train_f1:.4f}")

        # Validation
        pruned_model.eval()
        valid_loss = 0
        all_valid_preds = []
        all_valid_labels = []
        with torch.no_grad():
            for images, labels in tqdm(valid_loader, desc='Validation'):
                images, labels = images.to(device), labels.to(device)

                # Convert grayscale images to 3 channels
                if images.size(1) == 1:
                    images = images.repeat(1, 3, 1, 1)

                outputs = pruned_model(images)
                loss = criterion(outputs, labels)
                valid_loss += loss.item()

                all_valid_preds.append(outputs)
                all_valid_labels.append(labels)

        valid_loss /= len(valid_loader)
        valid_losses.append(valid_loss)
        valid_accuracy, valid_precision, valid_recall, valid_f1 = calculate_metrics(torch.cat(all_valid_preds), torch.cat(all_valid_labels))
        valid_accuracies.append(valid_accuracy)
        all_valid_precisions.append(valid_precision)  # Store valid_precision
        all_valid_recalls.append(valid_recall)        # Store valid_recall
        all_valid_f1s.append(valid_f1)

        print(f"Validation Loss: {valid_loss:.4f}, Accuracy: {valid_accuracy:.2f}%, Precision: {valid_precision:.4f}, Recall: {valid_recall:.4f}, F1-Score: {valid_f1:.4f}")

        # Save the best model based on validation loss
        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            torch.save(pruned_model.state_dict(), '/content/drive/MyDrive/Best-pruning-model/best-pruned-vgg-50.pth')
            print("New best model saved")

        # End timer for training and validation, and accumulate the time
        end_epoch_time = time.time()
        epoch_time = end_epoch_time - start_epoch_time
        total_train_validation_time += epoch_time
        #print(f"Epoch Time (Training + Validation): {epoch_time:.2f} seconds")

    # Print total training and validation time
    print(f"Total Training + Validation Time: {total_train_validation_time:.2f} seconds")

    return train_losses, valid_losses, train_accuracies, valid_accuracies, all_train_precisions, all_train_recalls, all_train_f1s, all_valid_precisions, all_valid_recalls, all_valid_f1s # Return the stored metrics

# Load Model Hasil Pruning
pruned_path = '/content/drive/MyDrive/Best-pruning-model/pruned-vgg-50.pth'
pruned_model.load_state_dict(torch.load(pruned_path, map_location=device))
pruned_model = pruned_model.to(device)


# Fine-tuning model yang telah di-prune
num_epochs = 100  # Tentukan jumlah epoch untuk fine-tuning

# Training
train_losses, valid_losses, train_accuracies, valid_accuracies, train_precisions, train_recalls, train_f1s, valid_precisions, valid_recalls, valid_f1s = train_and_evaluate(pruned_model, train_loader, valid_loader, num_epochs=num_epochs)

# Simpan model setelah fine-tuning
torch.save(pruned_model.state_dict(), '/content/drive/MyDrive/Best-pruning-model/fine_tuned_pruned_vgg-50.pth')

# Plot training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Training Loss')
plt.plot(valid_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.show()

# Plot training and validation accuracy
plt.figure(figsize=(10, 5))
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(valid_accuracies, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')
plt.show()

# Hitung rata-rata metrik setelah semua epoch
average_train_loss = np.mean(train_losses)
average_valid_loss = np.mean(valid_losses)
average_train_accuracy = np.mean(train_accuracies)
average_valid_accuracy = np.mean(valid_accuracies)
average_train_precision = np.mean(train_precisions) # Calculate mean from stored values
average_valid_precision = np.mean(valid_precisions) # Calculate mean from stored values
average_train_recall = np.mean(train_recalls)     # Calculate mean from stored values
average_valid_recall = np.mean(valid_recalls)     # Calculate mean from stored values
average_train_f1 = np.mean(train_f1s)           # Calculate mean from stored values
average_valid_f1 = np.mean(valid_f1s)           # Calculate mean from stored values



# Display results training
print('--------------')
print(f'Training Accuracy: {average_train_accuracy:.2f}%')
print(f'Training Loss: {average_train_loss:.4f}')
print(f'Training Precision: {average_train_precision:.4f}')
print(f'Training Recall: {average_train_recall:.4f}')
print(f'Training F1-Score: {average_train_f1:.4f}')


# Display results validasi
print('--------------')
print(f'Validation Accuracy: {average_valid_accuracy:.2f}%')
print(f'Validation Loss: {average_valid_loss:.4f}')
print(f'Validation Precision: {average_valid_precision:.4f}')
print(f'Validation Recall: {average_valid_recall:.4f}')
print(f'Validation F1-Score: {average_valid_f1:.4f}')

def debug_pruned_weights(model):
    """
    Print out the number of filters and weights in each layer to ensure pruning is correctly applied.
    """
    for name, module in model.named_modules():
        if isinstance(module, nn.Conv2d):
            print(f"Layer: {name}, Weights Shape: {module.weight.shape}")

# Periksa model setelah pruning
debug_pruned_weights(pruned_model)

# Test the model

pruned_model.load_state_dict(torch.load('/content/drive/MyDrive/Best-pruning-model/fine_tuned_pruned_vgg-50.pth'))
pruned_model.eval()

# Start timer for testing
start_test_time = time.time()

test_loss = 0
all_test_preds = []
all_test_labels = []
correct = 0
total = 0
with torch.no_grad():
  for images, labels in tqdm(test_loader, desc='Testing'):
    images, labels = images.to(device), labels.to(device)

    # Convert grayscale images to 3 channels
    if images.size(1) == 1:
      images = images.repeat(1, 3, 1, 1)

    outputs = pruned_model(images)
    loss = criterion(outputs, labels)
    test_loss += loss.item()

    all_test_preds.append(outputs)
    all_test_labels.append(labels)

    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

test_loss /= len(test_loader)
test_accuracy, test_precision, test_recall, test_f1 = calculate_metrics(torch.cat(all_test_preds), torch.cat(all_test_labels))
print("\n---------------------------------------------------------------------------------------------\n")
print(f"Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1-Score: {test_f1:.4f}")

# End timer for testing and print the total time
end_test_time = time.time()
total_testing_time = end_test_time - start_test_time
print(f"Total Testing Time: {total_testing_time:.2f} seconds")

# Path dinamis untuk memuat model terbaik
#best_model_file = '/content/drive/MyDrive/Chest-CT-Data/best-model-vgg-clahe-0,001.pth' if IN_COLAB else 'best-model.pth'
# Start testing time
testing_start_time = time.time()

# Load the best model
pruned_model.load_state_dict(torch.load('/content/drive/MyDrive/Best-pruning-model/fine_tuned_pruned_vgg-50.pth'))
pruned_model.eval()

# Define class labels corresponding to the numerical labels
class_labels = [
    'Adenocarcinoma',
    'Large Cell Carcinoma',
    'Normal',
    'Squamous Cell Carcinoma'
]

predicted_probabilities = []
true_labels = []

test_loader_tqdm = tqdm(test_loader, desc="Testing")
with torch.no_grad():
    for images, labels in test_loader_tqdm:
        images, labels = images.to(device), labels.to(device)
        if images.dim() == 3:
            images = images.unsqueeze(1)
        images = images.repeat(1, 3, 1, 1)
        outputs = pruned_model(images)
        loss = criterion(outputs, labels)
        probabilities = nn.functional.softmax(outputs, dim=1)
        predicted_probabilities.append(probabilities)
        true_labels.append(labels)
        #test_loader_tqdm.set_postfix({"Batch Size": len(labels)})

# End testing time
total_testing_time = time.time() - testing_start_time
print(f"Total testing time: {total_testing_time:.2f} seconds")

# Calculate evaluation metrics
predicted_probabilities = torch.cat(predicted_probabilities)
true_labels = torch.cat(true_labels)
predicted_labels = torch.argmax(predicted_probabilities, dim=1)

accuracy = (predicted_labels == true_labels).float().mean().item()
precision = precision_score(true_labels.cpu(), predicted_labels.cpu(), average='weighted')
recall = recall_score(true_labels.cpu(), predicted_labels.cpu(), average='weighted')
f1 = f1_score(true_labels.cpu(), predicted_labels.cpu(), average='weighted')
conf_matrix = confusion_matrix(true_labels.cpu(), predicted_labels.cpu())

# Display results
print(f'Test Accuracy: {accuracy * 100:.2f}%')
print(f'Test Loss: {loss:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-Score: {f1:.4f}')
print(f'Confusion Matrix:\n{conf_matrix}')

# Plot confusion matrix using Matplotlib
fig, ax = plt.subplots(figsize=(12, 9))
cax = ax.matshow(conf_matrix, cmap='Blues')

# Menampilkan angka pada setiap sel dengan outline putih
for (i, j), val in np.ndenumerate(conf_matrix):
    text = ax.text(j, i, f'{val}', ha='center', va='center', color='black', fontsize=20, fontweight='bold')

    # Menambahkan outline putih di sekitar angka
    text.set_path_effects([path_effects.Stroke(linewidth=3, foreground='white'),
                           path_effects.Normal()])

fig.colorbar(cax)

# Set ticks dan ticklabels
ax.set_xticks(np.arange(len(class_labels)))
ax.set_yticks(np.arange(len(class_labels)))
ax.set_xticklabels(class_labels)
ax.set_yticklabels(class_labels)

plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()


# Total time for the whole process
#total_process_time = total_training_time + total_testing_time
#print(f"Total process time (training + testing): {total_process_time:.2f} seconds")

"""![image.png](data:image/png;base64,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)"""



'''
import time  # Import modul time

# Define the optimizer and loss function
optimizer = optim.SGD(pruned_model.parameters(), lr=0.001, momentum=0.8)
criterion = nn.CrossEntropyLoss()

# Function to calculate metrics (accuracy, precision, recall, F1-score)
def calculate_metrics(predictions, labels):
    preds = torch.argmax(predictions, dim=1).cpu().numpy()
    labels = labels.cpu().numpy()

    accuracy = (preds == labels).mean() * 100
    precision = precision_score(labels, preds, average='weighted', zero_division=1)
    recall = recall_score(labels, preds, average='weighted', zero_division=1)
    f1 = f1_score(labels, preds, average='weighted', zero_division=1)

    return accuracy, precision, recall, f1

# Function to train and evaluate the model
def train_and_evaluate(pruned_model, train_loader, valid_loader,  num_epochs=100):
    train_losses = []
    valid_losses = []
    train_accuracies = []
    valid_accuracies = []
    all_train_precisions = []
    all_train_recalls = []
    all_train_f1s = []
    all_valid_precisions = []
    all_valid_recalls = []
    all_valid_f1s = []

    best_valid_loss = float('inf')

    # Variable to accumulate total training and validation time
    total_train_validation_time = 0

    for epoch in range(1, num_epochs + 1):
        print(f'Epoch {epoch}/{num_epochs}')

        # Start timer for both training and validation
        start_epoch_time = time.time()

        # Training
        pruned_model.train()
        train_loss = 0
        all_train_preds = []
        all_train_labels = []
        for images, labels in tqdm(train_loader, desc='Training'):
            images, labels = images.to(device), labels.to(device)

            # Convert grayscale images to 3 channels
            if images.size(1) == 1:  # If single channel
                images = images.repeat(1, 3, 1, 1)  # Repeat the channel dimension 3 times

            optimizer.zero_grad()
            outputs = pruned_model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

            all_train_preds.append(outputs)
            all_train_labels.append(labels)

        train_loss /= len(train_loader)
        train_losses.append(train_loss)
        train_accuracy, train_precision, train_recall, train_f1 = calculate_metrics(torch.cat(all_train_preds), torch.cat(all_train_labels))
        train_accuracies.append(train_accuracy)
        all_train_precisions.append(train_precision) # Store train_precision
        all_train_recalls.append(train_recall)       # Store train_recall
        all_train_f1s.append(train_f1)             # Store train_f1

        print(f"Training Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1-Score: {train_f1:.4f}")

        # Validation
        pruned_model.eval()
        valid_loss = 0
        all_valid_preds = []
        all_valid_labels = []
        with torch.no_grad():
            for images, labels in tqdm(valid_loader, desc='Validation'):
                images, labels = images.to(device), labels.to(device)

                # Convert grayscale images to 3 channels
                if images.size(1) == 1:
                    images = images.repeat(1, 3, 1, 1)

                outputs = pruned_model(images)
                loss = criterion(outputs, labels)
                valid_loss += loss.item()

                all_valid_preds.append(outputs)
                all_valid_labels.append(labels)

        valid_loss /= len(valid_loader)
        valid_losses.append(valid_loss)
        valid_accuracy, valid_precision, valid_recall, valid_f1 = calculate_metrics(torch.cat(all_valid_preds), torch.cat(all_valid_labels))
        valid_accuracies.append(valid_accuracy)
        all_valid_precisions.append(valid_precision)  # Store valid_precision
        all_valid_recalls.append(valid_recall)        # Store valid_recall
        all_valid_f1s.append(valid_f1)

        print(f"Validation Loss: {valid_loss:.4f}, Accuracy: {valid_accuracy:.2f}%, Precision: {valid_precision:.4f}, Recall: {valid_recall:.4f}, F1-Score: {valid_f1:.4f}")

        # Save the best model based on validation loss
        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            torch.save(pruned_model.state_dict(), '/content/drive/MyDrive/Best-pruning-model/best-pruned-vgg-10.pth')
            print("New best model saved")

        # End timer for training and validation, and accumulate the time
        end_epoch_time = time.time()
        epoch_time = end_epoch_time - start_epoch_time
        total_train_validation_time += epoch_time
        #print(f"Epoch Time (Training + Validation): {epoch_time:.2f} seconds")

    # Print total training and validation time
    print(f"Total Training + Validation Time: {total_train_validation_time:.2f} seconds")

    return train_losses, valid_losses, train_accuracies, valid_accuracies, all_train_precisions, all_train_recalls, all_train_f1s, all_valid_precisions, all_valid_recalls, all_valid_f1s # Return the stored metrics